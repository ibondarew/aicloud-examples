{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.1.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.1.1%2Bcu121-cp39-cp39-linux_x86_64.whl (2200.7 MB)\n",
      "Collecting torchvision==0.16.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.16.1%2Bcu121-cp39-cp39-linux_x86_64.whl (6.8 MB)\n",
      "Collecting torchaudio==2.1.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.1.1%2Bcu121-cp39-cp39-linux_x86_64.whl (3.3 MB)\n",
      "Collecting filelock (from torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/user/conda/lib/python3.9/site-packages (from torch==2.1.1) (4.10.0)\n",
      "Collecting sympy (from torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: jinja2 in /home/user/conda/lib/python3.9/site-packages (from torch==2.1.1) (3.1.3)\n",
      "Collecting fsspec (from torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "Requirement already satisfied: numpy in /home/user/conda/lib/python3.9/site-packages (from torchvision==0.16.1) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/user/conda/lib/python3.9/site-packages (from torchvision==0.16.1) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/user/conda/lib/python3.9/site-packages (from torchvision==0.16.1) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/conda/lib/python3.9/site-packages (from jinja2->torch==2.1.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/conda/lib/python3.9/site-packages (from requests->torchvision==0.16.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.9/site-packages (from requests->torchvision==0.16.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests->torchvision==0.16.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests->torchvision==0.16.1) (2024.2.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.1.1)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, triton, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.2.0 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.1.1+cu121 torchaudio-2.1.1+cu121 torchvision-0.16.1+cu121 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data as dt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "import mlflow\n",
    "import requests\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# BASE_DIR will be like '/home/jovyan/DemoExample/'\n",
    "BASE_DIR = pathlib.Path().absolute()\n",
    "print(f\"Working dir: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(url, filename):\n",
    "    # Download file and place it on local storage\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"{filename} downloaded from {url}\")\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"No internet connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(\"https://github.com/sbercloud-ai/aicloud-examples/raw/master/quick-start/notebooks_gpu/mnist.npz\", BASE_DIR.joinpath(\"mnist.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(BASE_DIR.joinpath('mnist.npz'))\n",
    "mnist_images_train = np.expand_dims(data['x_train'], 1)\n",
    "mnist_labels_train = data['y_train']\n",
    "\n",
    "mnist_images_test = np.expand_dims(data['x_test'], 1)\n",
    "mnist_labels_test = data['y_test']\n",
    "data.close()\n",
    "\n",
    "dataset_train = dt.TensorDataset(torch.Tensor(mnist_images_train), torch.Tensor(mnist_labels_train).long())\n",
    "dataset_test = dt.TensorDataset(torch.Tensor(mnist_images_test), torch.Tensor(mnist_labels_test).long())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=50)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    \"\"\"Custom module for a simple convnet classifier\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.dropout(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CNNClassifier()\n",
    "device = torch.device(f'cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataParallel if several GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    clf = nn.DataParallel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d-%H_%M\")\n",
    "writer = SummaryWriter(log_dir=BASE_DIR.joinpath('logs/log_' + current_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(clf.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, clf, optimizer, writer):\n",
    "    clf.train()  # set model in training mode (need this because of dropout)\n",
    "\n",
    "    # dataset API gives us pythonic batching\n",
    "    for batch_id, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # forward pass, calculate loss and backprop!\n",
    "        optimizer.zero_grad()\n",
    "        preds = clf(data)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            print(f'train loss = {loss.item()}')\n",
    "            writer.add_scalar('Train', loss.item(), epoch * len(train_loader) + batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, clf, writer):\n",
    "    clf.eval()  # set model in inference mode (need this because of dropout)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = clf(data)\n",
    "        test_loss += F.nll_loss(output, target).item()\n",
    "        pred = output.data.max(1)[1]  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    \n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader)  # loss function already averages over batch size\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    \n",
    "    \n",
    "    mlflow.log_metric(\"Test loss\", test_loss)  # add mlflow metrics\n",
    "    mlflow.log_metric(\"Accuracy\", np.round(accuracy.item(),1)) # add mlflow metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "print(f'Start train {num_epochs} epochs total')\n",
    "\n",
    "# Loading from checkpoint\n",
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "last_epoch = 0\n",
    "import os\n",
    "for root, dirs, files in os.walk(BASE_DIR.joinpath('logs')):\n",
    "    saved_models = [model_filename for model_filename in files if \".bin\" in model_filename]\n",
    "\n",
    "if saved_models:\n",
    "    checkpoint = torch.load(os.path.join(root, saved_models[-1]))\n",
    "    clf.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    print(f\"Continue training from {last_epoch} epoch\")\n",
    "\n",
    "# Start training\n",
    "mlflow.set_tracking_uri('file:/home/jovyan/mlruns')\n",
    "mlflow.set_experiment(\"pytorch_tensorboard_mlflow.ipynb\")\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "    for epoch in range(num_epochs):\n",
    "        if last_epoch:\n",
    "            epoch += last_epoch + 1\n",
    "\n",
    "        print(\"Epoch %d\" % epoch)\n",
    "        train(epoch, clf, optimizer, writer)\n",
    "        test(epoch, clf, writer)\n",
    "        # Save checkpoint every epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': clf.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, BASE_DIR.joinpath('logs/log_' + current_time + f\"/model_epoch_{epoch}.bin\"))\n",
    "        writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
