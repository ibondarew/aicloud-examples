# Знакомство с сервисом ML Space от Cloud.ru

Примеры из данного раздела позволят пользователям научиться отправке задач для распределенного обучения моделей.

* [Обучение модели в Jupyter Server с GPU](notebooks_gpu) рассказывает о том, как обучать модель напрямую из Jupyter Server, подключенного к GPU задействуя `Pytorch`, `Tensorboard`, `MLFlow`.
* [Обучение модели через Training Job API](job_launch) показывает, как создать и запустить задачу распределенного обучения (`Training Job`) на `Horovod` и `TensorFlow 1`.
* [Аналогичный пример](job_launch_tf2) показывает, как создать и запустить задачу распределенного обучения (`Training Job`) на `Horovod` и `TensorFlow 2`.
* [Обучение модели через Training Job API на CPU кластере](job_launch_cpu) показывает, как создать и запустить задачу не требующую GPU.


У каждого из этих способов обучения есть свои преимущества. Так при отправке задачи обучения на кластер можно задействовать до 1000 GPU, в случае обучения напрямую из Jupyter Server максимальное количество выделенных GPU — 16. Однако обучение из Jupyter Server на выделенных GPU проще и удобнее для пользователя (не требуется знакомство с библиотекой Horovod). Есть некоторые отличия в плане тарификации. При обучении из Jupyter Server на выделенных GPU взимается оплата до удаления сервера, даже если он не используется. При отправке задачи обучения на кластер пользователь платит за фактическое время исполнения задачи: от старта до окончания обучения.